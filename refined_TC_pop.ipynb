{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "refined_TC_pop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tYP9zSubkkI",
        "colab_type": "code",
        "outputId": "1081cde4-1a2e-475f-dcc2-a183eba01fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get install libgeos-3.5.0\n",
        "!apt-get install libgeos-dev\n",
        "!pip install https://github.com/matplotlib/basemap/archive/master.zip\n",
        "!pip install pyproj==1.9.6\n",
        "\n",
        "!pip install rasterio\n",
        "\n",
        "!apt-get install libproj-dev proj-data proj-bin\n",
        "!apt-get install libgeos-dev\n",
        "!pip install cython\n",
        "!pip install cartopy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package libgeos-3.5.0\n",
            "E: Couldn't find any package by glob 'libgeos-3.5.0'\n",
            "E: Couldn't find any package by regex 'libgeos-3.5.0'\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgdal-doc\n",
            "The following NEW packages will be installed:\n",
            "  libgeos-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 28 not upgraded.\n",
            "Need to get 73.1 kB of archives.\n",
            "After this operation, 486 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgeos-dev amd64 3.6.2-1build2 [73.1 kB]\n",
            "Fetched 73.1 kB in 1s (49.6 kB/s)\n",
            "Selecting previously unselected package libgeos-dev.\n",
            "(Reading database ... 132681 files and directories currently installed.)\n",
            "Preparing to unpack .../libgeos-dev_3.6.2-1build2_amd64.deb ...\n",
            "Unpacking libgeos-dev (3.6.2-1build2) ...\n",
            "Setting up libgeos-dev (3.6.2-1build2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting https://github.com/matplotlib/basemap/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/matplotlib/basemap/archive/master.zip\n",
            "\u001b[K     / 178.8MB 1.4MB/s\n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.1,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from basemap==1.2.1) (3.1.1)\n",
            "Requirement already satisfied: numpy>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from basemap==1.2.1) (1.17.3)\n",
            "Collecting pyproj>=1.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/b1/ab67ad924770e1c1432fa0953a665b8ea193b60c7494457b69da052d6e83/pyproj-2.4.0-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 2.8MB/s \n",
            "\u001b[?25hCollecting pyshp>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/16/3bf15aa864fb77845fab8007eda22c2bd67bd6c1fd13496df452c8c43621/pyshp-2.1.0.tar.gz (215kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from basemap==1.2.1) (1.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.1,>=1.0.0->basemap==1.2.1) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.1,>=1.0.0->basemap==1.2.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.1,>=1.0.0->basemap==1.2.1) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.1,>=1.0.0->basemap==1.2.1) (2.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.1,>=1.0.0->basemap==1.2.1) (41.4.0)\n",
            "Building wheels for collected packages: basemap, pyshp\n",
            "  Building wheel for basemap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basemap: filename=basemap-1.2.1-cp36-cp36m-linux_x86_64.whl size=121756044 sha256=65c4b4cc2a544908c934c5c04da789b02f7cc23a778519221d82dc46fdca7c4e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jqtt4ufm/wheels/98/4a/fc/ce719b75d97e646645c225f3332b1b217536100314922e9572\n",
            "  Building wheel for pyshp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyshp: filename=pyshp-2.1.0-cp36-none-any.whl size=32607 sha256=e7bc4652fabbc91c1226683b0bb0f86ac94b586d3c532e6eaa31e715c74ba21f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/0c/de/321b5192ad416b328975a2f0385f72c64db4656501eba7cc1a\n",
            "Successfully built basemap pyshp\n",
            "Installing collected packages: pyproj, pyshp, basemap\n",
            "Successfully installed basemap-1.2.1 pyproj-2.4.0 pyshp-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyproj==1.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8c/1da0580f334718e04f8bbf74f0515a7fb8185ff96b2560ce080c11aa145b/pyproj-1.9.6.tar.gz (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyproj\n",
            "  Building wheel for pyproj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyproj: filename=pyproj-1.9.6-cp36-cp36m-linux_x86_64.whl size=3702068 sha256=82878d6350732e95f1013dd51fcba39b2e5c0e187d3e47fbcdf41eab62a9cecc\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/cd/b1/a2d6430f74c7a778a43d62f78bec109ca69c732dc9b929142a\n",
            "Successfully built pyproj\n",
            "Installing collected packages: pyproj\n",
            "  Found existing installation: pyproj 2.4.0\n",
            "    Uninstalling pyproj-2.4.0:\n",
            "      Successfully uninstalled pyproj-2.4.0\n",
            "Successfully installed pyproj-1.9.6\n",
            "Collecting rasterio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/b5/a526d414acc152b2152731c28dbff6700e43d730d08b9ebc17a77c8fd939/rasterio-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (15.1MB)\n",
            "\u001b[K     |████████████████████████████████| 15.1MB 160kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rasterio) (1.17.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from rasterio) (19.3.0)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
            "Collecting click-plugins\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from rasterio) (7.0)\n",
            "Collecting affine\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.2)\n",
            "Installing collected packages: snuggs, click-plugins, affine, cligj, rasterio\n",
            "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.5.0 rasterio-1.1.0 snuggs-1.4.7\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "proj-data is already the newest version (4.9.3-2).\n",
            "proj-data set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  libproj-dev proj-bin\n",
            "0 upgraded, 2 newly installed, 0 to remove and 28 not upgraded.\n",
            "Need to get 232 kB of archives.\n",
            "After this operation, 1,220 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libproj-dev amd64 4.9.3-2 [199 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 proj-bin amd64 4.9.3-2 [32.3 kB]\n",
            "Fetched 232 kB in 3s (89.1 kB/s)\n",
            "Selecting previously unselected package libproj-dev:amd64.\n",
            "(Reading database ... 132697 files and directories currently installed.)\n",
            "Preparing to unpack .../libproj-dev_4.9.3-2_amd64.deb ...\n",
            "Unpacking libproj-dev:amd64 (4.9.3-2) ...\n",
            "Selecting previously unselected package proj-bin.\n",
            "Preparing to unpack .../proj-bin_4.9.3-2_amd64.deb ...\n",
            "Unpacking proj-bin (4.9.3-2) ...\n",
            "Setting up libproj-dev:amd64 (4.9.3-2) ...\n",
            "Setting up proj-bin (4.9.3-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgeos-dev is already the newest version (3.6.2-1build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.13)\n",
            "Collecting cartopy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/92/fe8838fa8158931906dfc4f16c5c1436b3dd2daf83592645b179581403ad/Cartopy-0.17.0.tar.gz (8.9MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9MB 2.7MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cartopy) (41.4.0)\n",
            "Requirement already satisfied: pyshp>=1.1.4 in /usr/local/lib/python3.6/dist-packages (from cartopy) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from cartopy) (1.17.3)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from cartopy) (1.12.0)\n",
            "Requirement already satisfied: shapely>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from cartopy) (1.6.4.post2)\n",
            "Building wheels for collected packages: cartopy\n",
            "  Building wheel for cartopy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cartopy: filename=Cartopy-0.17.0-cp36-cp36m-linux_x86_64.whl size=9714081 sha256=9209e8fc2c29accd634a1542333af2f80f1e07f7943aeb943a423c6fa5e3764a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/cf/40/539f798f94e921e94fd376a5f9d213a6febe77754c0b187c73\n",
            "Successfully built cartopy\n",
            "Installing collected packages: cartopy\n",
            "Successfully installed cartopy-0.17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tWq6-oSMz_3",
        "colab_type": "code",
        "outputId": "ea7cca03-e07c-409a-973d-38c925ab81dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql9faYy2cVsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rasterio\n",
        "import gdal\n",
        "\n",
        "from pyproj import Proj, transform\n",
        "from scipy.io import loadmat\n",
        " \n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.io.img_tiles as cimgt\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "\n",
        "from numpy import meshgrid\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJWoF2A3ckP0",
        "colab_type": "code",
        "outputId": "a5d73873-36ac-4310-b394-9dcf2cbb0435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "dset_gtiff = \"/content/drive/My Drive/Data/gpw_v4_population_count_rev11_2020_2pt5_min.tif\"\n",
        "gdal.AllRegister()\n",
        "global ds\n",
        "ds = gdal.Open(dset_gtiff)\n",
        "band = ds.GetRasterBand(1)\n",
        "arr = band.ReadAsArray()\n",
        "ds_size = arr.shape\n",
        "if band.GetMinimum() is None or band.GetMaximum() is None:\n",
        "   band.ComputeStatistics(0)\n",
        "      \n",
        "print (\"[ NO DATA VALUE ] = \", band.GetNoDataValue()) # none\n",
        "print (\"[ MIN ] = \", band.GetMinimum())\n",
        "print (\"[ MAX ] = \", band.GetMaximum())\n",
        "print (ds_size)\n",
        "\n",
        "ds.GetProjection()\n",
        "dataGTIFF = ds.ReadAsArray()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ NO DATA VALUE ] =  -3.4028230607370965e+38\n",
            "[ MIN ] =  0.0\n",
            "[ MAX ] =  1710353.125\n",
            "(4320, 8640)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIgwlk2Fc9X6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### From Documentation\n",
        "The population count data are divided by the land area data to create the population density rasters for each respective year. The pixels used in GPWv4 are quadrilaterals and therefore the area of each pixel decreases with increasing latitude. Additionally, the pixels in the land area data that include water reflect the net land area (total area of pixel – area of water within the pixel). This means that the population density data cannot be multiplied by a fixed land area size to estimate population totals without introducing error in some or all of the pixels. Multiplying the population density values by pixel area will overestimate population in pixels that contain water. If a fixed value for pixel area is used, it will also over or underestimate population totals for pixels that are all land as the area of these pixels varies by latitude. The population density data are best used to determine statistics (minimum, maximum, mean, etc.) within varying geographies. Users who need population totals should use the GPWv4 population count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF68heXUdX8G",
        "colab_type": "text"
      },
      "source": [
        "### Visualization on the Projection for People-Hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acYxoxYb3Dbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gather_data():\n",
        "  all_data = [loadmat('/content/drive/My Drive/Data/TrackData_RMM_phase' + str(i + 1) + '.mat') for i in range(8)]\n",
        "  eight_phase = []\n",
        "  for dset in all_data:\n",
        "    dset_lat = [row for row in dset['latstore']]\n",
        "    dset_long = [row for row in dset['longstore']]\n",
        "    hur_path = [zip(dset_lat[a], dset_long[a]) for a in range(4000)]\n",
        "    eight_phase.append(hur_path)\n",
        "  return eight_phase\n",
        "\n",
        "def transform_coordinate(j, i, padfTransform):\n",
        "  Yp = padfTransform[0] + i*padfTransform[1] + i*padfTransform[2];\n",
        "  Xp = padfTransform[3] + j*padfTransform[4] + j*padfTransform[5];\n",
        "  if Yp < 0:\n",
        "    Yp += 360\n",
        "  if Yp > 360:\n",
        "    Yp -= 360\n",
        "  return (Xp, Yp)\n",
        "\n",
        "def population_binning(data, width = 1.25):\n",
        "  pop_bins = np.zeros((int(90/width), int(280/width)))\n",
        "  for i in range(len(data) // 2):\n",
        "    for j in range(len(data[i])):\n",
        "      coords = transform_coordinate(i, j, ds.GetGeoTransform())\n",
        "      try:\n",
        "        if (0 <= coords[0] <= 90) and (0 <= coords[1] <= 280) and data[i][j] >= 1:\n",
        "          pop_bins[int(coords[0] / width)][int(coords[1] / width)] += round(data[i][j])\n",
        "      except:\n",
        "        print(coords)\n",
        "  return pop_bins\n",
        "\n",
        "def check_same_bin(x1, y1, x2, y2, width):\n",
        "  return int(x1/width) == int(x2/width) and int(y1/width) == int(y2/width) \n",
        "\n",
        "def hour_binning(hurr_phases, width = 1.25):\n",
        "  all_data = []\n",
        "  for phase in hurr_phases:\n",
        "    hour_bins = np.zeros((int(90/width), int(280/width))) #setting up a 2d-array for binning.\n",
        "    for hurricane in phase:\n",
        "      hurricane = list(hurricane)\n",
        "      hurricane = [coord for coord in hurricane if coord[0] != 0. and coord[1] != 0.]\n",
        "      for i in range(len(hurricane[1:])):\n",
        "        prev = hurricane[i-1]\n",
        "        if check_same_bin(prev[0], prev[1], hurricane[i][0], hurricane[i][1], width):\n",
        "          hour_bins[int(hurricane[i][0]/width)][int(hurricane[i][1] / width)] += 1\n",
        "        else:\n",
        "          split_hour(hour_bins, int(prev[0]/width), int(prev[1]/width), int(hurricane[i][0]/width), int(hurricane[i][1]/width))\n",
        "    all_data.append(hour_bins)\n",
        "  all_data = np.array([[[float('nan') if num < 1 else num for num in row] for row in data] for data in all_data])\n",
        "  return all_data\n",
        "\n",
        "def split_hour(hurr_phases, coord1x, coord1y, coord2x, coord2y):\n",
        "  dx = coord2x - coord1x\n",
        "  dy = coord2y - coord1y\n",
        "  increment = 1 /(abs(dx) + abs(dy))\n",
        "  incx, incy = 0,0\n",
        "  hurr_phases[coord1x][coord1y] += increment\n",
        "  while(dx != 0 or dy != 0):\n",
        "      if(abs(dx) == abs(dy)):\n",
        "        while(dx != 0 and dy !=0):\n",
        "          incx += 1 if dx > 0 else -1\n",
        "          incy += 1 if dy > 0 else -1\n",
        "          hurr_phases[coord1x+incx][coord1y+incy] += increment\n",
        "          dx -= 1 if dx > 0 else -1\n",
        "          dy -= 1 if dy > 0 else -1\n",
        "      else:\n",
        "        if(abs(dx) > abs(dy)):\n",
        "          incx += 1 if dx > 0 else -1\n",
        "          dx -= 1 if dx > 0 else -1\n",
        "          hurr_phases[coord1x+incx][coord1y+incy] += increment\n",
        "        elif (abs(dy) > abs(dx)):\n",
        "          incy += 1 if dy > 0 else -1\n",
        "          dy -= 1 if dy > 0 else -1\n",
        "          hurr_phases[coord1x+incx][coord1y+incy] += increment\n",
        "\n",
        "def popxhours(population, hour_set):\n",
        "  pop_hour_bins = [population*phase for phase in hour_set]\n",
        "  pop_hour_bins = [[[float('nan') if np.isnan(num) or num <= 1 else num for num in row] for row in data] for data in pop_hour_bins]\n",
        "  return np.array(pop_hour_bins)\n",
        "\n",
        "def popxhours_anomaly(pop_hour_bins, percentage = False): \n",
        "  sum_pop_hours = np.zeros(pop_hour_bins.shape[1:])\n",
        "  phases_participated = np.zeros(pop_hour_bins.shape[1:]) #Need to get the number of phases each bin has been in\n",
        "  for i in range(sum_pop_hours.shape[0]):\n",
        "    for j in range(sum_pop_hours.shape[1]):\n",
        "      vals = [phase[i,j] for phase in pop_hour_bins if not np.isnan(phase[i,j])]\n",
        "      sum_pop_hours[i,j] = np.nansum(vals)\n",
        "      phases_participated[i,j] = len(vals)\n",
        "  sum_pop_hours = np.array([[sum_pop_hours[i,j] / phases_participated[i,j] if phases_participated[i,j] > 0 else float('nan') for j in range(len(sum_pop_hours[i]))]for i in range(sum_pop_hours.shape[0])])\n",
        "  all_data = []\n",
        "  \n",
        "  for phase in pop_hour_bins:\n",
        "    phase_data = np.zeros(pop_hour_bins.shape[1:])\n",
        "    for i in range(phase_data.shape[0]):\n",
        "      for j in range(phase_data.shape[1]):\n",
        "        if not percentage:\n",
        "          phase_data[i,j] = float('nan') if np.isnan(sum_pop_hours[i,j]) else phase[i,j] - sum_pop_hours[i,j]\n",
        "        elif percentage and phases_participated[i,j] == 8:\n",
        "          phase_data[i,j] = float('nan') if np.isnan(sum_pop_hours[i,j]) else phase[i,j] - sum_pop_hours[i,j]\n",
        "          phase_data[i,j] = phase_data[i,j] * 100 /sum_pop_hours[i,j]\n",
        "        else:\n",
        "          phase_data[i,j] = float('nan')\n",
        "    all_data.append(phase_data)\n",
        "  return all_data\n",
        "\n",
        "def make_nans(threeDarr):\n",
        "  return [[[float('nan') if np.isnan(num) else num for num in row] for row in data] for data in threeDarr]\n",
        "  \n",
        "def create_maps(plot_labels, width = 1.25):\n",
        "  arr_with_nans = make_nans(plot_labels['data'])\n",
        "  y = np.arange(0,90, width)\n",
        "  x = np.arange(0,280,width)\n",
        "  for i in range(len(arr_with_nans)):\n",
        "    fig = plt.figure(figsize = (10, 8))\n",
        "    hm = Basemap(projection='lcc', resolution='c',\n",
        "            width=21E6, height=10E6, \n",
        "            lat_0=35, lon_0=145)\n",
        "    hm.shadedrelief(scale = 0.125)\n",
        "    parallels = np.arange(-90, 91, 10)\n",
        "    hm.drawparallels(parallels, labels = [True, False, False, False])\n",
        "    meridians = np.arange(0, 361,10)\n",
        "    hm.drawmeridians(meridians, lables = [False, False, True, True])\n",
        "    xx,yy = meshgrid(x,y) #the colormap and colorbar will be different depending on anomaly's value\n",
        "    hm.pcolormesh(xx,yy, arr_with_nans[i], latlon=True, cmap= plot_labels['cmapscheme'])\n",
        "    hm.drawcoastlines()\n",
        "    plt.clim(plot_labels['cmapmin'], plot_labels['cmapmax'])\n",
        "    plt.colorbar(label= plot_labels['cmaplabel'])\n",
        "    plt.title(plot_labels['label'] + ' - Phase %d' %(i+ 1))\n",
        "  \n",
        "def data_dict(data = None, label=None, xaxis=None, yaxis=None, cmapscheme=None, cmapmin=None, cmapmax=None, cmaplabel=None):\n",
        "  ps = {}\n",
        "  ps['data'] = data\n",
        "  ps['label'] = label\n",
        "  ps['xaxis'] = xaxis\n",
        "  ps['yaxis'] = yaxis\n",
        "  ps['cmapscheme'] = cmapscheme\n",
        "  ps['cmapmin'] = cmapmin\n",
        "  ps['cmapmax'] = cmapmax\n",
        "  ps['cmaplabel'] = cmaplabel\n",
        "  return ps\n",
        "\n",
        "def create_maps_subplotted(population_reference, hour_exposure, hour_anomalies, pop_hours, pop_hours_anomaly, pop_hours_diff, width = 1.25):\n",
        "  y = np.arange(0,90, width)\n",
        "  x = np.arange(0,280,width)\n",
        "  xx,yy = meshgrid(x,y)\n",
        "  parallels = np.arange(-90, 91, 10)\n",
        "  meridians = np.arange(0, 361,10)\n",
        "  pop = np.array([[float('nan') if num <= 0 else num for num in row] for row in population_reference])\n",
        "  for i in range(8):\n",
        "    plt.figure(figsize = (45, 30))\n",
        "    plt.subplot(3,2,1)\n",
        "    hm = Basemap(projection='lcc', resolution='c',\n",
        "            width=21E6, height=10E6, \n",
        "            lat_0=35, lon_0=145)\n",
        "    hm.shadedrelief(scale = 0.125)\n",
        "    hm.drawparallels(parallels, labels = [True, False, False, False])\n",
        "    hm.drawmeridians(meridians, lables = [False, False, True, True])\n",
        "    hm.pcolormesh(xx,yy, hour_exposure['data'][i], latlon=True, cmap= hour_exposure['cmapscheme'])\n",
        "    hm.drawcoastlines()\n",
        "    plt.clim(hour_exposure['cmapmin'], hour_exposure['cmapmax'])\n",
        "    plt.colorbar(label= hour_exposure['cmaplabel'])\n",
        "    plt.title(hour_exposure['label'] + ' - Phase %d' %(i+ 1))\n",
        "    \n",
        "    plt.subplot(3,2,2)\n",
        "    hm = Basemap(projection='lcc', resolution='c',\n",
        "            width=21E6, height=10E6, \n",
        "            lat_0=35, lon_0=145)\n",
        "    hm.shadedrelief(scale = 0.125)\n",
        "    hm.drawparallels(parallels, labels = [True, False, False, False])\n",
        "    hm.drawmeridians(meridians, lables = [False, False, True, True])\n",
        "    hm.pcolormesh(xx,yy, hour_anomalies['data'][i], latlon=True, cmap= hour_anomalies['cmapscheme'])\n",
        "    hm.drawcoastlines()\n",
        "    plt.clim(hour_anomalies['cmapmin'], hour_anomalies['cmapmax'])\n",
        "    plt.colorbar(label= hour_anomalies['cmaplabel'])\n",
        "    plt.title(hour_anomalies['label'] + ' - Phase %d' %(i+ 1)) \n",
        "    \n",
        "    plt.subplot(3,2,3)\n",
        "    hm.shadedrelief(scale = 0.125)\n",
        "    hm.drawparallels(parallels, labels = [True, False, False, False])\n",
        "    hm.drawmeridians(meridians, lables = [False, False, True, True])\n",
        "    hm.pcolormesh(xx,yy, pop_hours['data'][i], latlon=True, cmap= pop_hours['cmapscheme'])\n",
        "    hm.drawcoastlines()\n",
        "    plt.clim(pop_hours['cmapmin'], pop_hours['cmapmax'])\n",
        "    plt.colorbar(label= pop_hours['cmaplabel'])\n",
        "    plt.title(pop_hours['label'] + ' - Phase %d' %(i+ 1)) \n",
        "  \n",
        "    plt.subplot(3,2,4)\n",
        "    hm.shadedrelief(scale = 0.125)\n",
        "    hm.drawparallels(parallels, labels = [True, False, False, False])\n",
        "    hm.drawmeridians(meridians, lables = [False, False, True, True])\n",
        "    hm.pcolormesh(xx,yy, pop_hours_anomaly['data'][i], latlon=True, cmap= pop_hours_anomaly['cmapscheme'])\n",
        "    hm.drawcoastlines()\n",
        "    plt.clim(pop_hours_anomaly['cmapmin'], pop_hours_anomaly['cmapmax'])\n",
        "    plt.colorbar(label= pop_hours_anomaly['cmaplabel'])\n",
        "    plt.title(pop_hours_anomaly['label'] + ' - Phase %d' %(i+ 1))\n",
        "  \n",
        "    plt.subplot(3,2,5)\n",
        "    hm.shadedrelief(scale = 0.125)\n",
        "    hm.drawparallels(parallels, labels = [True, False, False, False])\n",
        "    hm.drawmeridians(meridians, lables = [False, False, True, True])\n",
        "    hm.pcolormesh(xx,yy, pop, latlon=True, cmap= 'YlGn')\n",
        "    hm.drawcoastlines()\n",
        "    plt.clim(np.nanmin(pop), 10000000)\n",
        "    plt.colorbar(label= 'People')\n",
        "    plt.title('Binned Population') \n",
        "\n",
        "    plt.subplot(3,2,6)\n",
        "    hm.shadedrelief(scale = 0.125)\n",
        "    hm.drawparallels(parallels, labels = [True, False, False, False])\n",
        "    hm.drawmeridians(meridians, lables = [False, False, True, True])\n",
        "    hm.pcolormesh(xx,yy, pop_hours_diff['data'][i], latlon=True, cmap= pop_hours_diff['cmapscheme'])\n",
        "    hm.drawcoastlines()\n",
        "    plt.clim(pop_hours_diff['cmapmin'], pop_hours_diff['cmapmax'])\n",
        "    plt.colorbar(label= pop_hours_diff['cmaplabel'])\n",
        "    plt.title(pop_hours_diff['label'] + ' - Phase %d' %(i+ 1))\n",
        "    \n",
        "import cv2\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "# from IPython.display import HTML\n",
        "# figure out .avi / .mp4 and embedding within IPython file\n",
        "# desired: create function so that this can be called on certain files\n",
        "def create_video(videoname):\n",
        "  image_folder = \"/content/\"\n",
        "  video_name = videoname + '.mp4'\n",
        "\n",
        "  images = [img for img in sorted(os.listdir(image_folder)) if img.endswith(\".png\")]\n",
        "  frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "  height, width, layers = frame.shape\n",
        "\n",
        "  video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
        "\n",
        "  for image in images:\n",
        "      video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "  cv2.destroyAllWindows()\n",
        "  video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edmX63D1SvXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hour_set = hour_binning(gather_data())\n",
        "hour_set_plots = data_dict(hour_set,'Hours Exposed', None, None, 'rainbow', np.nanmin(np.array(hour_set)), np.nanmax(np.array(hour_set)), 'Hours')\n",
        "\n",
        "hour_anom = popxhours_anomaly(hour_set, True)\n",
        "set_0 = abs(np.nanmax(np.array(hour_anom))) if abs(np.nanmax(np.array(hour_anom))) > abs(np.nanmin(np.array(hour_anom))) else abs(np.nanmin(np.array(hour_anom)))\n",
        "hour_anomaly_plots = data_dict(hour_anom, 'Hours Exposed Anomaly', None, None, 'RdBu', -set_0, set_0, 'Percent Difference From Mean')\n",
        "\n",
        "binned_pop = population_binning(dataGTIFF)\n",
        "all_data = popxhours(binned_pop, hour_set)\n",
        "all_data = np.log10(all_data)\n",
        "pop_hours_data = data_dict(all_data,'Population-Hours', None, None, 'rainbow', np.nanmin(np.array(all_data)), np.nanmax(np.array(all_data)), 'Person-Hours')\n",
        "\n",
        "anom = popxhours_anomaly(all_data, True)\n",
        "set_0 = abs(np.nanmax(np.array(anom))) if abs(np.nanmax(np.array(anom))) > abs(np.nanmin(np.array(anom))) else abs(np.nanmin(np.array(anom)))\n",
        "anomaly_dataset = data_dict(anom, 'Population Hour Anomaly', None, None, 'RdBu', -set_0, set_0, 'Percent Difference From Mean')\n",
        "\n",
        "non_percentage = popxhours_anomaly(all_data, False)\n",
        "limit_difference = abs(np.nanmax(np.array(non_percentage))) if abs(np.nanmax(np.array(non_percentage))) > abs(np.nanmin(np.array(non_percentage))) else abs(np.nanmin(np.array(non_percentage)))\n",
        "diff_dataset = data_dict(non_percentage, 'Population Hour Anomaly', None, None, 'RdBu', -limit_difference, limit_difference, 'Difference From Mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPrf2q_2SwCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_anom_std = np.nanstd(hour_anomaly_plots['data'])\n",
        "hour_anomaly_plots['cmapmin'] = -np.nanpercentile(hour_anomaly_plots['data'], 98.75)\n",
        "hour_anomaly_plots['cmapmax'] =  np.nanpercentile(hour_anomaly_plots['data'], 98.75)\n",
        "p_anom_std = np.nanstd(anomaly_dataset['data'])\n",
        "anomaly_dataset['cmapmin'] = -np.nanpercentile(anomaly_dataset['data'], 98.75)\n",
        "anomaly_dataset['cmapmax'] =  np.nanpercentile(anomaly_dataset['data'], 98.75)\n",
        "pop_hours_data['cmapmin'] =  0\n",
        "pop_hours_data['cmapmax'] =  np.nanpercentile(pop_hours_data['data'], 98.75)\n",
        "\n",
        "diff_dataset['cmapmin'] = -np.nanpercentile(diff_dataset['data'], 97)\n",
        "diff_dataset['cmapmax'] =  np.nanpercentile(diff_dataset['data'], 97)\n",
        "\n",
        "#diff anomaly dataset and houranomaly seem to be off?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YOPdbXQxJEZ",
        "colab_type": "text"
      },
      "source": [
        "### Data Variables\n",
        "* `binned pop`     - binned population grid\n",
        "* `hour_set_plots` - binned hours\n",
        "* `hour_anomaly_plots` - hour anomalies (phase hours - mean hours) / mean\n",
        "* `pop_hours_data` - binned hours * binned population grid\n",
        "* `anomaly_dataset` - population hour anomalies (same as hour_anomaly but focuses on population centers)\n",
        "* `diff_dataset` - raw difference (phase - mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud2ZIA0365wS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_maps_subplotted(binned_pop, hour_set_plots, hour_anomaly_plots, pop_hours_data, anomaly_dataset, diff_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-3UkVciPfwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "# create_maps_subplotted(binned_pop, hour_set_plots, hour_anomaly_plots, pop_hours_data, anomaly_dataset, diff_dataset)\n",
        "create_maps(pop_hours_data)\n",
        "#all lines (besides the last line) must be uncommented to create the video\n",
        "#in the next code block\n",
        "\n",
        "figures=[manager.canvas.figure\n",
        "       for manager in mpl._pylab_helpers.Gcf.get_all_fig_managers()]\n",
        "for i, figure in enumerate(figures):\n",
        "  figure.savefig('suplots_%d.png' % i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IvXk1nShYT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_video('6_figs')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}